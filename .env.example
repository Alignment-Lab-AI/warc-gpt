#-------------------------------------------------------------------------------
# LLM APIs settings
#-------------------------------------------------------------------------------
# NOTE: WARC-GPT needs to be able to interact with at least 1 LLM API.
OLLAMA_API_URL="http://localhost:11434" # Allows for running models locally. See: https://ollama.ai/
#OPENAI_API_KEY="" 
#OPENAI_ORG_ID=""

#ANTHROPIC_API_KEY=""

#COHERE_API_KEY=""

#PERPLEXITYAI_API_KEY=""

#-------------------------------------------------------------------------------
# Prompts
#-------------------------------------------------------------------------------
RAG_PROMPT="
Here is context:
{context}
----------------
Context comes from web pages that were captured as part of a web archives collection. 
When possible, use context to answer the question asked by the user.
If you don't know the answer, just say that you don't know, don't try to make up an answer. 
Ignore context if it is empty or irrelevant.
When possible and relevant, use context to cite or direct quote your sources.

Question: {question}

Helpful answer:"
# Inspired by LangChain's default prompt. {context} and {question} are reserved keywords.
# NOTE: An earlier vection of WARC-GPT used ALL CAPS CONTEXT, and QUESTION keywords.

#-------------------------------------------------------------------------------
# Paths
#-------------------------------------------------------------------------------
WARC_FOLDER_PATH="./warc"
VISUALIZATIONS_FOLDER_PATH="./visualizations"
VECTOR_SEARCH_PATH="./chromadb"

#-------------------------------------------------------------------------------
# Vector Store / Search settings
#-------------------------------------------------------------------------------
VECTOR_SEARCH_COLLECTION_NAME="collection"

VECTOR_SEARCH_SENTENCE_TRANSFORMER_MODEL="intfloat/e5-large-v2" # Can be any Sentence-Transformers compatible model available on Hugging Face
VECTOR_SEARCH_SENTENCE_TRANSFORMER_DEVICE="cpu"
VECTOR_SEARCH_DISTANCE_FUNCTION="cosine" # https://docs.trychroma.com/usage-guide#changing-the-distance-function
VECTOR_SEARCH_NORMALIZE_EMBEDDINGS="true"
VECTOR_SEARCH_CHUNK_PREFIX="passage: " # Can be used to add prefix to text embeddings stored in vector store
VECTOR_SEARCH_QUERY_PREFIX="query: " # Can be used to add prefix to text embeddings used for semantic search

VECTOR_SEARCH_TEXT_SPLITTER_CHUNK_OVERLAP=25 # Determines, for a given chunk of text, how many tokens must overlap with adjacent chunks.
VECTOR_SEARCH_SEARCH_N_RESULTS=4 # How many entries should the vector search return?

#-------------------------------------------------------------------------------
# Hugging Face's tokenizer settings
#-------------------------------------------------------------------------------
TOKENIZERS_PARALLELISM="false"
